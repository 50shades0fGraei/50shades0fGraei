{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCkNaF35piPnmRXrq5awFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/50shades0fGraei/50shades0fGraei/blob/main/Copy_of_Oly_GRAI_EL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "import gdown\n",
        "\n",
        "# a file\n",
        "url = \"https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ\"\n",
        "output = \"fcn8s_from_caffe.npz\"\n",
        "gdown.download(url, output)\n",
        "\n",
        "# same as the above, but with the file ID\n",
        "id = \"0B9P1L--7Wd2vNm9zMTJWOGxobkU\"\n",
        "gdown.download(id=id, output=output)\n",
        "\n",
        "# same as the above, and you can copy-and-paste a URL from Google Drive with fuzzy=True\n",
        "url = \"https://drive.google.com/file/d/0B9P1L--7Wd2vNm9zMTJWOGxobkU/view?usp=sharing\"\n",
        "gdown.download(url=url, output=output, fuzzy=True)\n",
        "\n",
        "# Cached download with identity check via MD5 (or SHA1, SHA256, etc).\n",
        "# Pass postprocess function e.g., extracting compressed file.\n",
        "md5 = \"md5:fa837a88f0c40c513d975104edf3da17\"\n",
        "gdown.cached_download(url, output, hash=hash, postprocess=gdown.extractall)\n",
        "\n",
        "# a folder\n",
        "url = \"https://drive.google.com/drive/folders/15uNXeRBIhVvZJIhL4yTw4IsStMhUaaxl\"\n",
        "gdown.download_folder(url)\n",
        "\n",
        "# same as the above, but with the folder ID\n",
        "id = \"15uNXeRBIhVvZJIhL4yTw4IsStMhUaaxl\"\n",
        "gdown.download_folder(id=id)\n",
        "# Load the EFWA.csv file\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=YOUR_FILE_ID'\n",
        "output = '/content/drive/MyDrive/EFWA.txt'\n",
        "gdown.download(url, output, quiet=False)\n",
        "df = pd.read_csv(output)\n",
        "\n",
        "Replace `YOUR_FILE_ID` with the actual ID of your Google Doc file. Shall I help with this process or any further steps?\n",
        "df = pd.read_csv('/content/drive/MyDrive/EFWA.txt')\n",
        "\n",
        "# Preprocess the text data\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def pre_process(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['text'] = df['text'].apply(pre_process)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a TF-IDF vectorizer to convert the text data into numerical features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier on the training data\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train a Support Vector Machine classifier on the training data\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Train a Random Forest classifier on the training data\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Implement debiasing techniques\n",
        "def debias_word_embeddings(word_embeddings):\n",
        "    # Implement debiasing technique here\n",
        "    pass\n",
        "\n",
        "# Implement emotion detection using NLP techniques\n",
        "def detect_emotions(text):\n",
        "    # Implement emotion detection technique here\n",
        "    pass\n",
        "\n",
        "# Implement interface to interact with LLM\n",
        "class LLMInterface:\n",
        "    def __init__(self, llm_model):\n",
        "        self.llm_model = llm_model\n",
        "\n",
        "    def generate_response(self, user_input):\n",
        "        # Implement response generation technique here\n",
        "        pass\n",
        "\n",
        "# Implement interface to interact with CNN\n",
        "class CNNInterface:\n",
        "    def __init__(self, cnn_model):\n",
        "        self.cnn_model = cnn_model\n",
        "\n",
        "    def analyze_input(self, user_input):\n",
        "        # Implement input analysis technique here\n",
        "        pass\n",
        "\n",
        "# Integrate components\n",
        "def integrate_components(user_input):\n",
        "    # Implement integration technique here\n",
        "    pass"
      ],
      "metadata": {
        "id": "Jl0430bxMlXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac60fed9-629a-44ab-b641-70012ed82d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ\n",
            "From (redirected): https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ&confirm=t&uuid=8cc8376e-5558-4631-adec-b7811e0489ab\n",
            "To: /content/fcn8s_from_caffe.npz\n",
            "100%|██████████| 499M/499M [00:07<00:00, 66.0MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B9P1L--7Wd2vNm9zMTJWOGxobkU\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9cd109055238>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# same as the above, but with the file ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0B9P1L--7Wd2vNm9zMTJWOGxobkU\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# same as the above, and you can copy-and-paste a URL from Google Drive with fuzzy=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B9P1L--7Wd2vNm9zMTJWOGxobkU\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "uDFh63gYFWSq",
        "outputId": "f34f0882-c72e-4db0-e8df-2b08e83237d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-4ba926643dc4>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-4ba926643dc4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Is it working\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KEJjDrgUFIaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v1g-nTTqFI6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6TzqANDiFJHZ"
      }
    }
  ]
}